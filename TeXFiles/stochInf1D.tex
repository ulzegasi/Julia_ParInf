\documentclass[11pt, a4paper]{article}

\usepackage{a4wide}
\usepackage{amsmath,amssymb,amsthm,amscd}
\usepackage{natbib}
\usepackage[pdftex]{graphicx}
\usepackage[affil-it]{authblk}
\usepackage{sidecap}
\usepackage[font=small,labelfont=bf]{caption}


%\usepackage{showkeys}

\usepackage[all]{xy}

\newcommand{\bb}[1]{\begin{equation}\label{#1}}
\newcommand{\ee}{\end{equation}}
\newcommand{\vc}[1]{{\bf #1 }}
\renewcommand{\vec}[1]{{\bf #1}}
\newcommand{\Sum}[1]{\sum\limits_{#1}}
\newcommand{\Int}[1]{\int\limits_{#1}}
\newcommand{\Prod}[1]{\prod\limits_{#1}}
\newcommand{\const}{\operatorname{const}}
\newcommand{\ul}{\underline}
\newcommand{\ol}{\overline}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\bbA}{\mathbb A}
\newcommand{\bbR}{\mathbb R}
\newcommand{\bbN}{\mathbb N}
\newcommand{\bbZ}{\mathbb Z}
\newcommand{\bbC}{\mathbb C}
\newcommand{\bbT}{\mathbb T}
\newcommand{\QB}{\mathcal H}
\newcommand{\PQB}{\tilde{\mathcal H}}
\newcommand{\CQB}{\mathcal H'}
\newcommand{\Ad}{\operatorname{Ad}}
\newcommand{\ad}{\operatorname{ad}}
\newcommand{\gh}{\operatorname{gh}}
\newcommand{\Der}{\operatorname{Der}}
\newcommand{\Aut}{\operatorname{Aut}}
\newcommand{\aut}{\operatorname{aut}}
\newcommand{\Diff}{\operatorname{Diff}}
\renewcommand{\dim}{\operatorname{dim}}
\newcommand{\Vol}{\operatorname{Vol}}
\newcommand{\Pf}{\operatorname{Pf}}
\newcommand{\Cov}{\operatorname{Cov}}

\newcommand{\g}{{\bf g}}
\newcommand{\h}{{\bf h}}
\renewcommand{\d}{{\bf d}}
\newcommand{\e}{{\bf e}}
\renewcommand{\t}{{\bf t}}
\newcommand{\lpartial}{\overset{\rightarrow}{\partial}}
\newcommand{\rpartial}{\overset{\leftarrow}{\partial}}
\newcommand{\lder}[1]{\overset{\rightarrow}{\vc #1}}
\newcommand{\rder}[1]{\overset{\leftarrow}{\vc #1}}
\newcommand{\supp}{\operatorname{supp}}
\newcommand{\im}{\operatorname{Im}}
\renewcommand{\ker}{\operatorname{Ker}}
\newcommand{\Var}{\operatorname{Var}}


%define the \identy operator
\def\litID{{\sf id}}
\def\identy{{\mathsurround0pt\mathchoice{\textidenty}{\textidenty}{\scptidenty}{\scptidenty}}}
\def\scptidenty{\setbox0\hbox{$\scriptstyle1$}\bothidenty}
\def\textidenty{\setbox0\hbox{$1$}\bothidenty}
\def\bothidenty{\rlap{\hbox to.97\wd0{\hss\vrule height.06\ht0 width.82\wd0}}
 \copy0\rlap{\kern-.36\wd0\vrule height1.05\ht0 width.05\ht0}\kern.14\wd0}
%end of definition \identy

\newcommand{\bbM}{\mathbb M}
\newcommand{\bt}{\pmb\theta}
\newcommand{\Bt}{\pmb\Theta}
\newcommand{\dt}{\mathit{dt}}
\newcommand{\eq}{\text{eq}}




\begin{document}
\title{Parameter Inference for a Simple Stochastic Hydrological Model}

\author{C. Albert\thanks{\noindent Email: carlo.albert@eawag.ch} \,,
S. Ulzega}
\affil{Eawag, Swiss Federal Institute of Aquatic Science and Technology, 8600 D\"ubendorf, Switzerland}
\maketitle

In this paper, we study the feasibility of a full Bayesian inference, for simple conceptual rainfall-runoff models with scale-invariant noise.
We start with a single linear reservoir and describe the dynamics of its water content, $S(t)$, by means of the stochastic differential equation
\begin{equation}\label{sde}
\dot{S}(t) = r(t) - \frac{1}{K}\left(1+\frac{\gamma}{2}\right) S(t)
+
\sqrt{\frac{\gamma}{K}} S(t){\eta}(t)\,,
\end{equation}
where $r(t)$ describes the rain input and $\eta(t)$ denotes white noise, i.e.,
\begin{equation}\label{whitenoise}
\langle\eta(t)\eta(t')\rangle = \delta(t-t')\,.
\end{equation}
Due to the state-dependence of the noise term, eq. (\ref{sde}) is ill-defined unless we specify the discretization convention.
For computational reasons, we work with the {\em Stratonovich} convention.
Our parametrization is such that, for constant rain input $r(t)=r_0$ and in the long-time limit, the mean of $S$ converges to the equilibrium solution of the unperturbed ($\gamma=0$) system, $S_{eq}=Kr_0$ (see below).

The scale-invariance of the noise term renders the noise parameter $\gamma$ dimensionless.
Before we proceed, we replace the state variable $S(t)$ and parameter $K$ by dimensionless quantities $q(t)$ and $\beta$, respectively, by means of the transformations
\begin{equation}
  \beta=\sqrt{\frac{T\gamma}{K}}\,,\quad
  S(t)=\frac{T\gamma r(t)}{\beta^2}e^{\beta q(t)}\,.
\end{equation}
W.r.t. these new  variables and parameters, model equation (\ref{sde}) becomes
\begin{equation}
  \dot q(t)
  =
  \frac{\beta}{T\gamma}e^{-\beta q(t)}
  -
  \frac{1}{T}\rho(t)
  +
  \frac{1}{\sqrt{T}}\eta(t)\,,
\end{equation}
with
\begin{equation}
  \rho(t)
  =
  \frac{T}{\beta}\frac{d}{dt}\ln r(t)
  +
  \frac{(2+\gamma)\beta}{2\gamma}\,.
\end{equation}


%Given rainfall and runoff time-series, we want to infer the two system parameters $K$ and $\gamma$, measuring, respectively, the retention time and the noise.


According to \cite{lau_2007_StateDepDiff}, the probability, $P(q_1,T|q_0,0)$, of finding the system in a state $q$ at time $t = T$ given that it was in an initial state $q_0$ at time $t = 0$, can be expressed in the form of a path integral as
\begin{equation}\label{pathint}
P(q_1,T|q_0,0) 
= 
\frac{1}{Z}
\int 
e^{-{\mathcal S}[q,\dot q]} 
\delta(q(T)-q_1)
\delta(q(0)-q_0)
\mathcal{D}q \,,
\end{equation}
where the integral extends over all paths $q:[0,T]\rightarrow \mathbb R$.
The path-measure $\mathcal Dq$ is formally written as an infinite product
\begin{equation}\label{pathmeasure_q}
{\mathcal Dq}
=
\prod_{t}
dq(t)\,.
\end{equation}
The {\em action} is a functional on the space of paths and reads as
%\begin{equation}\label{action}
%  \tilde{\mathcal S}[\dot{S}(t),S(t)]
%  =
%  \int_0^T
%  dt
%  \left\{
%    \frac{K}{2\gamma S^2(t)}
%    \left(
%        \dot S(t)
%        -
%        r(t)
%        +
%        \frac{1+\gamma}{K}S(t)
%    \right)^2
%    -
%    \frac{2+\gamma}{4K}
%  \right\}
% \,.
%\end{equation}
\begin{equation}
{\mathcal S}[{q},\dot q]
=
\frac{1}{T}
\int_0^T \dt \left\{
\frac{1}{2}
\left(
    T\dot q(t)
    +
    \rho(t)
    -
    \frac{\beta}{\gamma}e^{-\beta q(t)}\right)^2
    -
    \frac{\beta^2}{2\gamma}e^{-\beta q(t)}
\right\} \,.
\end{equation}
Note that the action includes the Jacobian that arises when changing coordinates from ${\eta(t)}$ to $q(t)$.

We introduce the time-dependent {\em Hamiltonian}
\begin{equation}\label{H}
  \mathcal{H}(q,t)
  =
  \frac{1}{\gamma}e^{-\beta q}+q\rho(t)\,,
\end{equation}
and rewrite action (\ref{action}) as,
\begin{multline}\label{action}
{\mathcal S}[{q},\dot q]
=
\frac{1}{T}
\int_0^T dt\left\{
    \frac{1}{2}
    T^2\dot q^2(t) +
    \frac{1}{2}
    \left(\rho(t)-\frac{\beta}{\gamma}e^{-\beta q(t)}\right)^2 -
    T\frac{\partial \mathcal{H}(q,t)}{\partial t} -
    \frac{\beta^2}{2\gamma}e^{-\beta q(t)}
     %\frac{(2+\gamma)\beta^2}{4\gamma}
\right\}
\\
+ \mathcal{H}(q(T),T) - \mathcal{H}(q(0),0)
\\
= \frac{1}{T}
\int_0^T dt\left\{
    \frac{1}{2}
    T^2\dot q^2(t) +
    \frac{1}{2}
    \left(\rho(t)-\frac{\beta}{\gamma}e^{-\beta q(t)}\right)^2 -
    Tq(t)\dot\rho(t) -
     \frac{\beta^2}{2\gamma}e^{-\beta q(t)}
%    \frac{(2+\gamma)\beta^2}{4\gamma}
\right\}
\\
+
    \frac{1}{\gamma}e^{-\beta q(T)}+q(T)\rho(T)
   -\frac{1}{\gamma}e^{-\beta q(0)}-q(0)\rho(0)
\,.
\end{multline}

Next, we calculate the equilibrium distribution $P_{\text{eq}}(q) = \lim_{T\rightarrow\infty} P(q,T|q_0,0)$ in the simple case of a constant rain input $r(t)\equiv r_{0}$. Systems at thermal equilibrium must fulfill detailed balance, i.e.,
\begin{equation}\label{detailed_balance}
P(q_1 t_1 | q_0 t_0 ) P_{\text{eq}}(q_0) = P(q_0 t_1 | q_1 t_0 ) P_{\text{eq}}(q_1) \,.
\end{equation}
After plugging in (\ref{pathint}) and (\ref{action}), and using the transformation $q(t) \rightarrow q(-t)$, which maps paths from $q_0$ to $q_1$ to paths from $q_1$ to $q_0$, we get, since $\dot\rho(t)= 0$,
\begin{equation}\label{Peq}
  P_{\text{eq}}(q)
  \propto
  e^{-2\mathcal{H}(q)}\,.
\end{equation}
Transforming back to the original variables, it turns out that $P_{\text{eq}}(S)$ is described by an inverse gamma distribution with scale parameter $2Kr_{0}/\gamma$ and shape parameter $(2+\gamma)/\gamma$, i.e.,
\begin{equation}\label{inverse_gamma}
  P_{\text{eq}}(S)
  \propto
  S^{-2(1+\gamma)/\gamma}e^{-2Kr_{0}/(\gamma S)}\,,
\end{equation}
whose mean equals the equilibrium solution of the unperturbed system ($\gamma=0$),
\begin{equation}
  \langle S\rangle_{\eq}=Kr_{0},
\end{equation}
and whose variance, for $\gamma< 2$, is given by
\begin{equation}
  \langle (S - \langle S\rangle_{\eq})^2\rangle_{\eq}
  =
  K^2r_{0}^2
  \frac{\gamma}{2-\gamma}\,.
\end{equation}
Note that the variance diverges, for $\gamma\geq 2$.
The power-law decay of the inverse gamma distribution is reminiscent of the scale-invariance of the error model.


Let us now consider two time-series of {\em observed} rain inputs and discharge outputs, $r_s=r(t_s)$ and $y_s=S(t_s)/K$, respectively, measured at times $0=t_1<t_2<\dots < t_{n+1}=T$.
For the measurement error model, we simply set
\begin{equation}\label{data}
  \ln\frac{y_s}{r_s}
  =
  \beta q_s
  +
  \sigma\epsilon_s\,,\quad s=1,\dots,n+1\,,
\end{equation}
where $\epsilon_s$ are uncorrelated standard normal random variables.


%The {\em likelihood} function for the data (\ref{data}) is, up to a factor that doesn't depend on the model parameters, given by the path-integral
%\begin{equation}\label{likelihood}
%  f(\vc y | \bt)
%  \propto
%  \int
%  \exp\bigg[
%    -{\tilde{\mathcal S}}[\dot{S},S]
%    -\frac{1}{2}
%    \sum_{i=1}^{n+1}
%    \frac
%    {(y_i-S(t_i)/K)^2}
%    {\sigma^2}
%  \bigg]
%  {\mathcal D} S(\bt)\,,
%\end{equation}
%with the parameter vector $\bt=(K,\gamma)^T$.
%Choosing for the parameters $K$ and $\gamma$ the improper prior given by
%
%\begin{equation}\label{prior}
%  f(\bt)
%  =  f(K) f(\gamma) = \frac{1}{K \gamma} \,,
%\end{equation}
%
%{\em parameter inference} means generating a sufficiently large sample of parameter vectors from the posterior
%\begin{equation}\label{posterior}
%  f(\bt|\vc y)\propto f(\vc y|\bt)f(\bt)\,.
%\end{equation}


The goal is to infer the posterior parameter distribution, for the parameters $\bt=(\beta,\gamma)^T$, based on the measured time series $\vc r$ and $\vc y$.
For the time being we assume constant priors.
Then, the posterior reads as
\begin{equation}\label{posterior_pathint}
  f(\bt | \vc y, \vc r)
  \propto
  \int
  \exp\bigg[
    -{{\mathcal S}}[{q},\dot q]
    -\frac{1}{2}
    \sum_{s=1}^{n+1}
    \frac
    {(\ln(y_s/r_s)-{\beta q_s})^2}
    {\sigma^2}
    %-\ln(K\gamma)
  \bigg]
  {\mathcal Dq}
  \,.
\end{equation}
Since the integral on the r.h.s. of (\ref{posterior_pathint}) is very expensive to calculate, we will sample, simultaneously, parameter vectors $\bt$ and discretized system realizations $q(t)$ directly from an appropriate discretization of the kernel of (\ref{posterior_pathint}).
Since the associated distribution is very high dimensional and strongly correlated, we employ the method called {\em Hamiltonian Monte Carlo} (HMC) introduced by \cite{duane_1987_HMC}.
This method interprets the exponent of the kernel of the posterior as the potential of a one-dimensional statistical mechanical system. Each degree of freedom, $q(t)$ and $\bt$ in our case, is paired with a conjugate variable, $p(t)$ and ${\pmb\pi}$, respectively, and the system is defined by the  Hamiltonian
\begin{equation}\label{Hamiltonian}
    \mathcal{H}_{\text{HMC}}(q,\bt; p,{\pmb\pi})
    =
    K( p,{\pmb\pi}) + V( q,\bt)\,,
\end{equation}
with
\begin{equation}\label{K}
   K( p,{\pmb\pi})
   =
   \int_0^T \frac{ p^2(t)}{2m_q}dt
   + \sum_{\alpha=1}^2\frac{\pi_\alpha^2}{2m_\alpha}\,,
\end{equation}
where $V( q,\bt)$ is the negative logarithm of the kernel of (\ref{posterior_pathint}).
The posterior (\ref{posterior_pathint}) is expressed by the phase space path integral
\begin{equation}\label{phaseSpacePathInt}
    f(\bt | \vc y, \vc r)
  \propto
  \int
  e^{-\mathcal {H}_{\text{HMC}}(q,\bt; p,{\pmb\pi})}
  {\mathcal Dp}
  \wedge
  {\mathcal Dq}
  \wedge
  d{\pmb\pi}
  \,.
\end{equation}

The HMC method, which is a combination of the {\em Metropolis algorithm} by \cite{metropolis_1953_MRT2} and {\em molecular dynamics} methods \textbf{[ref?]}, iterates the following steps
\begin{enumerate}
  \item
  Momenta are sampled from the Gaussian distribution defined by (\ref{K}).
  \item
  A volume-preserving and time-reversible solution to a discretization of Hamilton's equations is calculated numerically.
  \item
  The discretization error on the energy preservation due to the previous step is corrected by a Metropolis acceptance/rejection step.
\end{enumerate}
The last step is the standard Metropolis algorithm, while the first two steps allow us to make relatively large jumps in phase space while maintaining a relatively large acceptance rate.

Let us first write down the discretization of the path-integral (\ref{phaseSpacePathInt}).
Therefore, let us assume that the measurement time points $\left\{ y_s \right\}_{s=1,\dots, n+1}$ of the time series (\ref{data}) are equidistantly distributed on the time interval $[0,T]$, with $t_1=0$ and $t_{n+1}=T$.
Each interval between two consecutive data points is further partitioned into $j$ bins, such that we have a total of $nj+1=N>>1$ discretization points.
Path-integral (\ref{posterior_pathint}) is approximated by an ordinary integral, with the approximate path-measure 
\begin{equation}
  \mathcal Dp\wedge\mathcal Dq
  \approx
  \prod_i dp_i\wedge dq_i 
\end{equation}
and the discretized versions of $K( p,{\pmb\pi})$ and $V( q,\bt)$
\begin{align}
   K( p,{\pmb\pi})
   &\approx
   \sum_{i=1}^N
   \frac{ p_i^2}{2m_q}\Delta t
   +
   \sum_{\alpha=1}^2\frac{\pi_\alpha^2}{2m_\alpha}\,,\label{Kdisc}
   \\
   V(q,\bt)
   &\approx
   \frac{\Delta t}{T}
   \sum_{i=2}^{N}
   \left\{
    \frac{1}{2} 
    T^2 \dot q_i^2
    +
    \frac{1}{2}
     \left(
        \rho_i-\frac{\beta}{\gamma}e^{-\beta q_i}
     \right)^2
    -
    \frac{\beta^2}{2\gamma}
    e^{-\beta q_i}
   -
    T q_i\dot\rho_i
   \right\}
  \\
  &+
  \frac{1}{\gamma}
  e^{-\beta q_N}
  +
  q_N \rho_{N}
  -
  \frac{1}{\gamma}
  e^{-\beta q_1}
  -
  q_1 \rho_{1}
  \nonumber
  \\
  & +
  \sum_{s=1}^{n+1}
  \frac{(\ln(y_s/r_{(s-1)j+1}) - {\beta q_{(s-1)j+1}})^2}{2\sigma^2}
   \,,\label{Vdisc}
\end{align}
with
\begin{equation}
  \dot q_i = \frac{q_i-q_{i-1}}{\Delta t}\,,
  %\quad
%  \bar q_i = \frac{q_i+q_{i-1}}{2}\,,
\end{equation}
and
\begin{equation}\label{rhodisc}
\rho_i = \frac{T}{\beta} \frac{\ln(r_{i+1}/r_i)}{\Delta t}
+
\frac{(2+\gamma)\beta}{2\gamma}
\,,\quad
\dot\rho_i = \frac{\rho_i-\rho_{i-1}}{\Delta t}\,.
\end{equation}
Note that we've neglected terms of order $\mathcal O(N^{-1/2})$ in the action (\ref{Vdisc}) and that we've assumed $r_i$ to be the discretization of an at least twice differentiable interpolation of the input measurements.

%\begin{equation}
%  \dot{q}_i:=\frac{ q_i -  q_{i-1}}{\Delta t}\,,\quad
%  \bar{ q}_i:=\frac{q_i + q_{i-1}}{2}\,,
%\end{equation}
%and the analogous definition of $\dot r_i$ and $\bar r_i$.

For strongly varying rain input or high-frequency output data, $\Delta t$ needs to be chosen small. Thus, the harmonic part of the Hamiltonian becomes stiff and, consequently, the time-step of MD needs to be chosen small, which leads to slow convergence.
To solve this problem, we change coordinates, such that the harmonic part of the Hamiltonian becomes (partly) diagonal and the particle interaction moves to the potential.
One option would be to use the Fourier modes of ${\eta}(t)$ as configurational variables. Calculating the potential requires then an inversion of a Toeplitz matrix. This approach is interesting because, in our case, it allows for an approximate analytical integration of high-frequency modes (see \cite{doll_1985_fourier}).

We choose another approach, the so-called \emph{staging} as described in \cite{tuckerman1992reversible}, and diagonalize the harmonic part only in between the measurement points.
We first note that Hamiltonian (\ref{Hamiltonian}) can be seen as the classical Hamiltonian of a polymer chain with harmonic bonds between neighbouring beads, described by the first harmonic term of $V(q,\bt)$, in an external field described by the other non-harmonic terms of $V(q,\bt)$.
Furthermore, the model parameters are viewed as additional degrees of freedom that couple with all other degrees of freedom.
Sampling system realizations, each defined by a set of coordinates $\left\{ q_i\right\}$ and parameters $\bt$, is equivalent to sampling states in the polymer dynamics.

The discretized harmonic part of the action is rewritten as
\begin{multline}
  \sum_{i=2}^{N}
  \frac{T}{2\Delta t}
  (q_i-q_{i-1})^2
  \\ =
  \frac{T}{2}
  \sum_{s=1}^{n}\left\{
    \frac{(q_{(s-1)j+1} - q_{sj+1})^2}{j\Delta t}
    +
    \sum_{k=2}^j
    \frac{k}{(k-1)\Delta t}
    (q_{(s-1)j+k}-q^*_{(s-1)j+k})^2
  \right\}\,,
\end{multline}
with
\begin{equation}
  q^*_{(s-1)j+k}
  =
  \frac{(k-1)q_{(s-1)j+k+1} + q_{(s-1)j+1} }{k}
  \,.
\end{equation}
Following \cite{tuckerman1993efficient} we apply the coordinate transformation
\begin{equation}
  u_{sj+1} = q_{sj+1}\,,\quad
  u_{sj+k} = q_{sj+k} - q^*_{sj+k}\,,
\end{equation}
with its inverse given by
\begin{equation}
  q_{sj+1} = u_{sj+1}\,,\quad
  q_{sj+k} = \sum_{l=k}^{j+1}\frac{k-1}{l-1}u_{sj+l}
  +\frac{j-k+1}{j}u_{sj+1}\,,
\end{equation}
or equivalently by the recursive relation
\begin{equation}
  q_{sj+k} = u_{sj+k} + \frac{k-1}{k} q_{s+k+1}+ \frac{1}{k}q_{sj+1} \,.
\end{equation}
%Moreover, we introduce the following transformation for the parameters,
%
%\begin{equation}\label{params_transform}
%\beta = \ln(K/T) \,,\quad \tau=\ln(\gamma)
%\end{equation}
%
%and the corresponding transformed vector $\tilde{\bt}=(\beta,\tau)^T$. This transformation ensures that the system parameters $K$ and $\gamma$ will be kept positive during the HMC algorithm.
%

This transformation decouples fast degrees of freedom from slow ones and allows us to split the Hamiltonian $\mathcal H_{HMC}$ into components with different scaling behaviour in the potentially large numbers $n$ and $N$.
We write
\begin{equation}
  \mathcal H_{HMC}= \mathcal H_N+\mathcal H_n+\mathcal H_1\,,
\end{equation}
where
\begin{align}
  \mathcal H_N
  &=
  \frac{1}{2}
  \sum_{s=1}^{n}
  \sum_{k=2}^j
  \left\{
    \frac{\Delta t}{m_q}p_{(s-1)j+k}^2
    +
    \frac{Tk}{\Delta t(k-1)}
    u_{(s-1)j+k}^2
  \right\}\,,\label{H_N}
  \\
  \mathcal H_n
  &=
  \frac{1}{2}
  \sum_{s=1}^{n+1}
  \left\{
   \frac{\Delta t }{m_q}p_{(s-1)j+1}^2
    +
    \frac{T}{j\Delta t}
    (u_{(s-1)j+1} - u_{sj+1})^2
    -
    \frac{(\ln(y_s/r_{(s-1)j+1}) - {\beta u_{(s-1)j+1}})^2}{2\sigma^2}
   \right\}\,,\\
  \mathcal H_1
  &=
   \sum_{\alpha=1}^2\frac{\pi_\alpha^2}{2m_\alpha}
   +
  \frac{\Delta t}{T}
   \sum_{i=2}^{N}
   \left\{
    \frac{1}{2}
     \left(
        \rho_i-\frac{\beta}{\gamma}e^{-\beta q_i}
     \right)^2
    -
    \frac{\beta^2}{2\gamma}
    e^{-\beta q_i}
   -
    T q_i\dot\rho_i
   \right\}
  \\
  &+
  \frac{1}{\gamma}
  e^{-\beta q_N}
  +
  q_N \rho_{N}
  -
  \frac{1}{\gamma}
  e^{-\beta q_1}
  -
  q_1 \rho_{1}
\,.
\end{align}
The harmonic part $\mathcal H_N$, for the staging beads, scales linearly with $N$.
The harmonic term $\mathcal H_n$, for the boundary beads, as well as the measurement term scale linearly with $n$.
Finally, the potential does not scale with neither $n$ nor $N$.
Thus, depending on the values of $N$ and $n$, the dynamics happens on very different time scales.
Therefore, we use the Trotter formula according to \cite{tuckerman1992reversible} in order to design a reversible molecular dynamics integrator that takes these different time scales into account.
In order to design an appropriate partition of the Hamiltonian, we need to distinguish different regimes.
\begin{enumerate}
  \item[\it i.]
  $\mathcal H_N \sim \mathcal H_n >> \mathcal H_1$
  \item[\it ii.]
  $\mathcal H_N >> \mathcal H_n \sim \mathcal H_1$
  \item[\it iii.]
  $\mathcal H_N >> \mathcal H_n >> \mathcal H_1$
\end{enumerate}

In regime ($ii$) we simply separate the harmonic part of the action, for the staging beads, from the rest and write
\begin{equation}
  \mathcal H_{HMC}=\mathcal H_N + \mathcal H'\,.
\end{equation}
In order to design a reversible integrator, for the associated Hamiltonian equations, we define the Liouville operators
\begin{equation}
  iL_N=\{\cdot\,,\,\mathcal H_N\}\,,\quad
  iL'=\{\cdot\,,\,\mathcal H'\}\,,
\end{equation}
where $\{\cdot\,,\,\cdot\}$ denotes the Poisson brackets that are defined on functions on the phase space.
Trotter's formula allows us to write the Hamiltonian propagator as
\begin{equation}
  e^{i(L_N+L')\tau}
  =
  (e^{iL_N(\Delta\tau/2)}e^{iL'\Delta\tau}e^{iL_N(\Delta\tau/2)})^P
  +
  \mathcal O(P^{-2})\,,
\end{equation}
for $\tau =P\Delta \tau$.
In regime ($ii$) the outer propagator $\exp[iL_N(\Delta \tau/2)]$ describes a much faster dynamics than the inner one.
However, it is the dynamics of uncoupled harmonic oscillators, which we can readily solve.
Masses and frequencies of the oscillators are derived from (\ref{H_N}) as
\begin{equation}
  m=m_q/\Delta t\,,\quad
  \omega_k=\sqrt{\frac{Nk}{(k-1)m}}\,.
\end{equation}
The fast outer propagator is then given by eqs.
\begin{align}
  u_{(s-1)j+k}(\Delta\tau/2)
  &=
  u_{(s-1)j+k}(0)\cos(\omega_k\Delta\tau/2)
  +
  \frac{p_{(s-1)j+k}(0)}{m\omega_k}\sin(\omega_k\Delta\tau/2)\,,\\
  p_{(s-1)j+k}(\Delta\tau/2)
  &=
  p_{(s-1)j+k}(0)\cos(\omega_k\Delta\tau/2)
  -
  m\omega_k u_{(s-1)j+k}(0) \sin(\omega_k\Delta\tau/2)\,,
\end{align}
for $k=2,\dots,j$.

For the inner, slow propagator, we employ the velocity Verlet algorithm.
For the boundary beads, it reads
\begin{align}
  u_{(s-1)j+1}(\Delta\tau)
  &=
  u_{(s-1)j+1}(0)
  +
  \frac{\Delta\tau}{m} p_{(s-1)j+1}(0)
  +
  \frac{\Delta \tau^2}{2m}
  F_{(s-1)j+1}[\vc u(0),{\pmb\theta}(0)]\,,\\
  p_{(s-1)j+1}(\Delta\tau)
  &=
  p_{(s-1)j+1}(0)
  +
  \frac{\Delta\tau}{2}
  (
  F_{(s-1)j+1}[\vc u(0),{\pmb\theta}(0)]
  +
  F_{(s-1)j+1}[\vc u(\Delta\tau),{\pmb\theta}(\Delta\tau)]
  )\,,
\end{align}
where $F_i[\vc u,{\pmb\theta}]$ denotes the partial derivative of $\mathcal H'[\vc u,{\pmb\theta}]$ w.r.t. $u_i$.
For the model parameters, analogous equations apply.
When it comes to the staging beads, however, only the momenta have to be updated, because the associated kinetic term is not part of $\mathcal H'$ but of $\mathcal H_N$.
Thus,
\begin{equation}
  p_{(s-1)j+k}(\Delta\tau)
  =
  p_{(s-1)j+k}(0)
  +
  \frac{\Delta\tau}{2}
  (
  F_{(s-1)j+k}[\vc u(0),{\pmb\theta}(0)]
  +
  F_{(s-1)j+k}[\vc u(\Delta\tau),{\pmb\theta}(\Delta\tau)]
  )
  \,.
\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%We can now fully exploit the two different time-scales that are involved in the problem. First, the harmonic part of the fast component ${\mathcal V}_f[\dot{\vc u},\vc u]$ can be seen as describing the dynamics of heavy coupled \emph{boundary} data-point beads and lighter uncoupled \emph{staging} beads. The different weights of boundary and staging beads are defined by adjusting their \emph{effective masses}, $m_{\text{bdy}}$ and $m_{\text{st}}$, respectively. These values are used in (\ref{Kdisc}) for the masses $m_{q}$.
%Second, the two different ranges of the forces associated with ${\mathcal V}_f(\vc u,\tilde{\bt})$ and ${\mathcal V}_s(\vc q,\tilde{\bt})$ can be efficiently taken into account by applying a reversible reference system propagator algorithm (RESPA), as outlined in Tuckerman et al. (1992). The RESPA algorithm, based on appropriate reversible molecular dynamics integrators, can significantly accelerate simulations of systems that are simultaneously subject to short- and long-range forces by separating the two different time-scales.

%The basic idea of the RESPA algorithm is to apply a Trotter decomposition to the system Liouville propagator $\mathcal{L}$ to generate a discrete time propagator factorized into fast and slow contributions. Indeed, as shown in Tuckerman et al. (1992), the propagator $\exp[i \mathcal{L} \Delta \tau ]$ can be written as

%\begin{equation}\label{G}
%  \mathcal{G}(\Delta \tau)=\exp\left\{ \frac{\Delta \tau}{2} F_s(x) \frac{\partial}{\partial p} \right\} \exp\left\{ i \mathcal{L}_f \Delta \tau  \right\} \exp\left\{ \frac{\Delta \tau}{2} F_s(x) \frac{\partial}{\partial p} \right\}\,,
%\end{equation}
%
%where for the sake of clarity we have assumed a one-dimensional system. The argument can be easily extended to our multi-dimensional case. In (\ref{G}) $F_s$ is the force associated with the slowly varying long-range potential ${\mathcal V}_s$ and $\mathcal{L}_f = \dot{x}(\partial/\partial x) + F_f(x)(\partial/\partial p)$ is the Liouville operator of the fast short-range potential ${\mathcal V}_f$. The propagator of the slow force $F_s$ can be well approximated with a large time step $\Delta \tau$. On the other hand, in order to ensure stable dynamics, the short-range middle propagator is further factorized into $n_f$ smaller time steps of duration $\delta \tau = \Delta \tau / n_f$, according to the Trotter expansion
%
%\begin{equation}\label{G_fast}
%  \exp\left\{ i \mathcal{L}_f \Delta \tau  \right\}
%  =\left[
%  \exp\left\{ \frac{\delta \tau}{2} F_f(x) \frac{\partial}{\partial p} \right\}
%  \exp\left\{  \delta\tau \dot{x} \frac{\partial}{\partial x}  \right\}
%  \exp\left\{  \frac{\delta \tau}{2} F_f(x) \frac{\partial}{\partial p} \right\}
%  \right]^{n_f} \,.
%\end{equation}
%
%Coordinates and conjugate momenta, i.e., $(q,\bt; p,{\pmb\pi})$ in our case, are propagated using (\ref{G}) and (\ref{G_fast}) iteratively by applying a velocity Verlet algorithm.
%
\textbf{Some preliminary results}. The results shown in the figures refer to synthetic data obtained assuming a simple sinusoidal model for the rain input. The experimental data were then generated using the "true" parameter values $K=200$ and $\gamma = 0.2$. We considered $n=51$ data points, $j=10$ staging points, and therefore $N=501$ discretization points. The total time $T$ is $\approx 833$ [units of time], so that the discretization points are separated by a time interval $\Delta t \approx 1.6 $ [units of time]. Following the RESPA method described above, we used a long time step $\Delta \tau = 0.02$ [units of time] for the evolution of the slow (long-range) potential, further subdivided in 16 smaller steps for the evolution of the fast (short-range) potential.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{Figs/FigRainData.png}
    \caption{Rain input (dashed), system realization (solid line) and synthetic experimental data. The system output and the observed data were generated using $K=200$ and $\gamma = 0.2$.}
    \label{fig:rain_data_S}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{Figs/FigSpaghetti.png}
    \caption{Simulated system realizations and synthetic experimental data obtained assuming a simple sinusoidal model for the rain input. In the inset one may appreciate the different dynamics of the heavy data-point beads and the light staging beads.}
    \label{fig:spaghetti}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{Figs/FigFinalState.png}
    \caption{PDF for the system final state expressed via the coordinate set $\left\{ q_N \right\}$. The dashed curve represents a normal distribution with the same mean and variance. The final state is basically normally distributed.}
    \label{fig:final_state}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{Figs/FigChains.png}
    \caption{Markov chains for the two parameters $K$ (top) and $\gamma$ (bottom).}
    \label{fig:chains}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{Figs/FigPhaseSpaceEvol.png}
    \caption{System dynamics in the phase space $K-\gamma$. The green dot is the initial state, the red dot is the final state, the yellow dots are the last 50 states of the HMC chain, and the orange square corresponds to the true parameter values used to generate the data.}
    \label{fig:phase_space_evol}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{Figs/FigKg.png}
    \caption{PDF for the parameters $K$ (left) and $\gamma$ (right). The true values used to generate the data are $K=200$ and $\gamma = 0.2$. The initial values used in the simulations were $K=50$ and $\gamma = 0.4$.}
    \label{fig:K_distr}
\end{figure}



\bibliographystyle{apalike} % chicago \shortcite(N)
\bibliography{C:/Users/albertca/SWITCHdrive/refs}


\end{document}
